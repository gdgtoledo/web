---
layout: post
title:  "Cansino"
date:   2020-03-16 13:00:00
description: Cansineando a los pol√≠ticos
author:
  name: Manuel de la Pe√±a
  twitter: mdelapenya
---

A veces los pol√≠ticos y las pol√≠ticas de turno hablan mucho sobre lo que ellos dicen que es importante para la ciudadan√≠a, y a su vez, muchas otras veces encontramos que no hacen lo que dicen.

Por ello, se me ha ocurrido el acceder a las agendas p√∫blicas de ciertos pol√≠ticos, en particular presidentes de comunidades aut√≥nomas, hacer un scrapping de las mismas puesto que **no ofrecen un API p√∫blico para consultarlas**, y almacenar los eventos de cada d√≠a en un repositorio. De esta manera, ser√≠amos capaces de consultar los citados eventos de una manera estructurada utilizando t√©cnicas de BigData, y verificar si lo que estos pol√≠ticos hacen (porque est√° en sus agendas) se alinea con lo que realmente prometen.

Es cierto que este enfoque tendr√≠a cierto sesgo al no publicar √©stos realmente lo que hacen, sino que se centran √∫nicamente en compartir un mero texto muy vago, con poca literatura: _'Asiste al consejo blah blah blah'_, supongo que para que no pillarse los dedos. Pero es lo que tenemos. ¬°Ya nos gustar√≠a que los gobernantes fueran m√°s transparentes y nos facilitaran m√°s informaci√≥n!

Con todo esto en la mano, queremos procesar esos eventos de las agendas, quitar las palabras de paso en castellano (preposiciones, conjunciones, etc.), y almacenar cada evento en un repositorio que permita realizar anal√≠ticas sobre este conjunto de datos. Y aprovechando que _Elasticsearch_ es un almacenamiento orientado a b√∫squedas, y que trabajo en [Elastic](https://www.elastic.co), qu√© mejor que aprovechar su potencia para almacenar en √©l las agendas, procesar el contenido, y mostrar gr√°ficos de inter√©s en _Kibana_, como por ejemplo una nube de tags con las palabras m√°s utilizadas. El resultado para Castilla-La Mancha, podr√≠a ser algo as√≠:

![Castilla-La Mancha Dashboard](/web/assets/images/posts/2020-04-16-cansino/dashboard-sample.png)

>Como pod√©is comprobar, muchos pol√≠ticos simplemente "asisten" a reuniones. Como ya dije antes, como ciudadano me encantar√≠a que fueran mucho m√°s transparentes de lo que en realidad son.

Es por ello que he llamado a este servicio **Cansino**, porque persigue de manera incansable al pol√≠tico de turno, como el famoso [Cansino Hist√≥rico de Jos√© Mota](http://www.josemota.com/personaje/el-cansino-historico/).

## Stack tecnol√≥gico

En cuanto al stack, os he dado unas pinceladas del almacenamiento primario, _Elasticsearch_, as√≠ como la aplicaci√≥n de visualizaci√≥n de datos, _Kibana_. Hablar√© de ellos m√°s adelante. Pero, ¬øc√≥mo cogemos, procesamos y enviamos las agendas al almacenamiento principal?

Aqu√≠ es donde aparece la palabra _scrap_, que no es otra cosa que coger el HTML completo de la p√°gina web donde se muestra un dato, y extraer del mismo la informaci√≥n necesaria seleccionando los elementos y tags HTML de inter√©s. Por tanto supone un an√°lisis previo de la estructura de la p√°gina, para identificar c√≥mo se presenta la informaci√≥n de inter√©s.

Es importante hacer una parada aqu√≠ para pedir encarecidamente que us√©is atributos ID de manera consistente: un √∫nico ID por p√°gina, y que utilic√©is un marcado HTML que no sea una aut√©ntica lasa√±a de elementos anidados sin sem√°ntica alguna. Dicho √©sto, vamos al programa que hace el scrapping.

**Cansino** es un programa escrito en Go que procesa documentos HTML, siendo este documento el correspondiente a la agenda para un d√≠a concreto del pol√≠tico de inter√©s. Para ello, coge cada evento de la agenda de ese d√≠a, extrae la informaci√≥n de inter√©s y la env√≠a al almacenamiento. Esta informaci√≥n de inter√©s se corresponde con los siguientes campos:

```
- id: representando un identificador √∫nico del evento.
- date: con la fecha y hora del evento.
- description: con las palabras clave de la descripci√≥n del evento.
- originalDescription: con la descripci√≥n original completa.
- location: con las palabras clave de la localizaci√≥n del evento.
- locationDescription: con la localizaci√≥n original completa.
- attendance: que es a su vez una estructura, una por persona asistente al evento, con los campos:
    - job: con el puesto de la persona.
    - fullName: con el nombre completo.
- owner: con el cargo de la persona due√±a de la agenda.
- region: con el nombre de la regi√≥n.
```

El scrapping es posible gracias a [Go-Colly](http://go-colly.org/), que facilita much√≠simo esta tarea. Sin embargo, en alg√∫n caso he necesitado utilizar [htmlquery](https://github.com/antchfx/htmlquery) para parsear directamente el HTML retornado por peticiones Ajax.

> En relaci√≥n a √©sto √∫ltimo, es muy frustrante ver c√≥mo la web de la Comunidad de Madrid se folla los verbos HTTP y utiliza POST para retornar los eventos de un d√≠a en particular ü§¶‚Äç‚ôÄÔ∏è.

![Agenda Madrid](/web/assets/images/posts/2020-04-16-cansino/agenda-madrid.png)

Una vez capturada la informaci√≥n de inter√©s, y modelada en una estructura de datos, la quiero indexar en _Elasticsearch_, por tanto hay que definir los tipos de datos de una manera consecuente a las operaciones que quiero realizar, que no es otra que hacer una b√∫squeda de tipo _full-text_ en la descripci√≥n y en la localizaci√≥n de los eventos, para saber de qu√© hablan nuestros pol√≠ticos y, tambi√©n importante, desde d√≥nde lo hacen. Por tanto, los tipos para cada campo son:

```
- id: keyword.
- date: date.
- description: text.
- originalDescription: keyword.
- location: text.
- locationDescription: keyword.
- attendance:
  - job: text.
  - fullName: text.
- owner: keyword.
- region: keyword.
```

Simplemente a√±adiendo [el cliente oficial de Go de Elasticsearch](https://github.com/elastic/go-elasticsearch) a la aplicaci√≥n es suficiente para indexar el dato, pero primero, nada m√°s capturar un evento de la web, lo analizo con un _Analyzer_, que es el responsable de quitar en la descripci√≥n y la localizaci√≥n las palabras de paso en castellano (adverbios, pronombres, preposiciones, conjunciones, etc.). Esta funcionalidad ya la trae de serie _Elasticsearch_, por tanto s√≥lo hay que definirlo en la definici√≥n del √≠ndice.

```json
    "settings": {
        "analysis": {
            "analyzer": {
                "spanish_stop": {
                    "type": "stop",
                    "stopwords": "_spanish_"
                }
            }
        }
    },
```

La carga inicial de todos los documentos, esto es, desde el primer d√≠a en el que tienen datos las agendas, la hice en mi equipo, pero he a√±adido una GitHub Action que se ejecuta cada d√≠a a ciertas horas, a modo de cron, para almacenar los eventos del d√≠a actual.

> Hay que reconocer que Extremadura tiene datos desde el 2011! Castilla-La Mancha conserva un hist√≥rico desde el 2017, y la Comunidad de Madrid desde el 2019.

Una cosa que he implementado para entender qu√© est√° pasando en **Cansino** mientras se ejecuta, consiste en instrumentar el c√≥digo con el [Agente de APM para Go de Elastic](https://www.elastic.co/guide/en/apm/agent/go/master/index.html), creando trazas de la aplicaci√≥n cada vez que se almacena un evento. De esta manera puedo saber los tiempos de ejecuci√≥n y el estado del runtime de Go, entre otras cosas.

![Transactions](/web/assets/images/posts/2020-04-16-cansino/transactions.png)
![Errors](/web/assets/images/posts/2020-04-16-cansino/errors.png)
![Metrics](/web/assets/images/posts/2020-04-16-cansino/metrics.png)
![Spans](/web/assets/images/posts/2020-04-16-cansino/spans.png)

Configurando el entorno para que las siguientes variables est√©n disponibles es m√°s que suficiente para decirle al agente d√≥nde tiene que enviar las trazas, m√©tricas y errores:

```shell
ELASTIC_APM_SECRET_TOKEN=<APM Token>
ELASTIC_APM_SERVER_URL=<URL del APM Server>
ELASTIC_APM_SERVICE_NAME=cansino
ELASTIC_APM_SERVICE_VERSION=1.0.0
ELASTIC_APM_CAPTURE_BODY=all
```

Para controlar el flujo de ejecuci√≥n del programa, **Cansino** es una CLI escrita utilizando [Cobra](https://github.com/spf13/cobra), con dos √∫nicos comandos:

- **chase**, que procesa todos los eventos desde los inicios de cada agenda.
- **get [-d|--date 2020-04-14]**, el cual procesa los eventos de un √∫nico d√≠a, pasado por par√°metro en formato _YYYY-MM-dd_. Si el valor de este par√°metro es igual a la cadena "Today", entonces se usar√° la fecha del sistema, cargando los eventos de hoy. Este comando es el utilizado por la GitHub Action para capturar los eventos del d√≠a.

## Despliegue y operaciones

Le doy un apartado especial a esto porque considero muy importante el operar un servicio. Si tenemos los conocimientos adecuados para asegurar la estabilidad del entorno, me parece bien que lo operemos nosotros mismos, pero y si falla el disco, o la memoria, o el servidor no responde a m√°s peticiones... SaaS to the rescue!

Podr√≠amos tener un [Elastic Stack](https://github.com/elastic/stack-docker) desplegado en la misma red que el **Cansino** para enviar los datos ah√≠, pero no tendr√≠a mucho valor el tenerlos en local. Mi idea es poder compartir esta informaci√≥n en alg√∫n momento, as√≠ que por ello, qu√© mejor opci√≥n que utilizar el [Cloud de Elastic](https://cloud.elastic.co) para alojar los datos, y que sean ellos los que lo operen por m√≠, con un modelo de pago por uso (ojo que tiene un trial de 15 d√≠as, ¬°aprovechadlo!). Es cierto que al ser empleado de Elastic tengo un cluster chiquitito para m√≠, y por eso he metido a **Cansino** aqu√≠, pero tambi√©n es verdad que utilizar Elastic Cloud en el arranque de un proyecto te puede ahorrar much√≠simo tiempo de setup y operaciones, para luego m√°s adelante ya decidir si quieres hacerlo in-house o continuar con el modelo cloud. En este cl√∫ster tengo un _Elasticsearch_, un _Kibana_, y un _APM Server_ (o middleware que recibe las trazas del agente de APM para Go, y se las env√≠a al _Elasticsearch_ en un formato conocido), por lo que con un par de click **Cansino** ya podr√≠a empezar a funcionar y enviar datos para ser procesados.

Para enviar los datos al Cloud hay que configurar el cliente de _Elasticsearch_ de la siguiente manera:

```go
    cfg := es.Config{
        // configuraci√≥n de Elastic Cloud
		CloudID:   os.Getenv("ELASTIC_CLOUD_ID"),
		Password:  os.Getenv("ELASTIC_CLOUD_AUTH"),
        Username:  os.Getenv("ELASTIC_CLOUD_USERNAME"),
        // configuraci√≥n para el agente de APM para Go
		Transport: apmes.WrapRoundTripper(http.DefaultTransport),
	}
    client, err := es.NewClient(cfg)
```

Y no hay nada m√°s que hacer ah√≠ üòä.

En cuanto a la parte de visualizaci√≥n, he creado varias visualizaciones espec√≠ficas en _Kibana_ en funci√≥n de lo que quer√≠a obtener, como por ejemplo:

- comparar n√∫meros de eventos en torno a ciertas fechas de inter√©s, como elecciones...
- nube de tags con las palabras m√°s utilizadas en las descripciones de los eventos de la agenda
- nube de tags con las palabras m√°s utilizadas en las localizaciones de los eventos de la agenda

¬°Pero estoy seguro que se te ocurren muchos m√°s!

## ¬øY qu√© regiones estoy analizando?

**Cansino** analiza, por el momento, tres regiones de Espa√±a:

- [Castilla-La Mancha](https://transparencia.castillalamancha.es/agenda/198) (mi regi√≥n!)
- [Extremadura](http://www.juntaex.es//web/agenda-presidencia)
- [Madrid](https://www.comunidad.madrid/agenda-gobierno)

## ¬øQu√© m√°s se podr√≠a hacer con el Stack?

Podr√≠amos adem√°s aumentar los logs de **Cansino** y enviarlos con [**Filebeat**](https://www.elastic.co/beats/filebeat) al Stack, de modo que pudi√©semos correlar eventos de log con trazas y/o m√©tricas de la aplicaci√≥n.

No soy para nada un experto en ML, pero seguro que podr√≠amos aplicar Machine Learning y aprender un poco de los eventos, su frecuencia y su tem√°tica, y observar anomal√≠as.

¬øSe os ocurre algo m√°s?

## ¬øY si quiero analizar qu√© dicen en mi regi√≥n?

Si quieres que a√±ada otra regi√≥n, please [abre una issue](https://github.com/mdelapenya/cansino/issues/new).

## ¬øQuieres acceder a los dashboards?

Si quieres acceder a un dashboard, please env√≠ame un email a _mdelapenya at gmail.com_.
